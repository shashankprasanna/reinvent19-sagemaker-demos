{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor analysis using Amazon SageMaker Debugger\n",
    "\n",
    "Looking at the distributions of activation inputs/outputs, gradients and weights per layer can give useful insights. For instance, it helps to understand whether the model runs into problems like neuron saturation, whether there are layers in your model that are not learning at all or whether the network consists of too many layers etc. \n",
    "\n",
    "The following animation shows the distribution of gradients of a convolutional layer from an example application  as the training progresses. We can see that it starts as Gaussian distribution but then becomes more and more narrow. We can also see that the range of gradients starts very small (order of $1e-5$) and becomes even tinier as training progresses. If tiny gradients are observed from the start of training, it is an indication that we should check the hyperparameters of our model. \n",
    "\n",
    "![](images/example.gif)\n",
    "\n",
    "In this notebook we will train a poorly configured neural network and use Amazon SageMaker Debugger with custom rules to aggregate and analyse specific tensors. Before we proceed let us install the smdebug binary which allows us to perform interactive analysis in this notebook. After installing it, please restart the kernel, and when you come back skip this cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the inputs for the training job\n",
    "\n",
    "Now we'll call the Sagemaker MXNet Estimator to kick off a training job . The `entry_point_script` points to the MXNet training script. The users can create a custom *SessionHook* in their training script. If they chose not to create such hook in the training script (similar to the one we will be using in this example) Amazon SageMaker Debugger will create the appropriate *SessionHook* based on specified *DebugHookConfig* parameters.\n",
    "\n",
    "The `hyperparameters` are the parameters that will be passed to the training script. We choose `Uniform(1)` as initializer and learning rate of `0.001`. This leads to the model not training well because the model is poorly initialized.\n",
    "\n",
    "The goal of a good intialization is \n",
    "- to break the symmetry such that parameters do not receive same gradients and updates\n",
    "- to keep variance similar across layers\n",
    "\n",
    "A bad intialization may lead to vanishing or exploiding gradients and the model not training at all. Once the training is finished we will look at the distirbutions of activation inputs/outputs, gradients and weights across the training to see how these hyperparameters influenced the training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_script = 'mnist.py'\n",
    "bad_hyperparameters = {'initializer': 2, 'lr': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker.debugger import DebuggerHookConfig, CollectionConfig\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "BUCKET_NAME = sagemaker_session.default_bucket()\n",
    "LOCATION_IN_BUCKET = 'smdebug-mnist-tensor-analysis'\n",
    "\n",
    "s3_bucket_for_tensors = 's3://{BUCKET_NAME}/{LOCATION_IN_BUCKET}'.format(BUCKET_NAME=BUCKET_NAME, LOCATION_IN_BUCKET=LOCATION_IN_BUCKET)\n",
    "estimator = MXNet(role=sagemaker.get_execution_role(),\n",
    "                  base_job_name='mxnet',\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.m5.xlarge',\n",
    "                  train_volume_size=400,\n",
    "                  source_dir='src',\n",
    "                  entry_point=entry_point_script,\n",
    "                  hyperparameters=bad_hyperparameters,\n",
    "                  framework_version='1.6.0',\n",
    "                  py_version='py3',\n",
    "                  debugger_hook_config = DebuggerHookConfig(\n",
    "                      s3_output_path=s3_bucket_for_tensors,  \n",
    "                      collection_configs=[\n",
    "                        CollectionConfig(\n",
    "                            name=\"all\",\n",
    "                            parameters={\n",
    "                                \"include_regex\": \".*\",\n",
    "                                \"save_interval\": \"100\"\n",
    "                            }\n",
    "                        )\n",
    "                     ]\n",
    "                   )\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get S3 location of tensors\n",
    "\n",
    "We can get information related to the training job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TrainingJobName': 'mxnet-2019-12-09-08-07-37-389',\n",
       " 'TrainingJobArn': 'arn:aws:sagemaker:us-west-2:453691756499:training-job/mxnet-2019-12-09-08-07-37-389',\n",
       " 'ModelArtifacts': {'S3ModelArtifacts': 's3://sagemaker-us-west-2-453691756499/mxnet-2019-12-09-08-07-37-389/output/model.tar.gz'},\n",
       " 'TrainingJobStatus': 'Completed',\n",
       " 'SecondaryStatus': 'Completed',\n",
       " 'HyperParameters': {'initializer': '2',\n",
       "  'lr': '0.001',\n",
       "  'sagemaker_container_log_level': '20',\n",
       "  'sagemaker_enable_cloudwatch_metrics': 'false',\n",
       "  'sagemaker_job_name': '\"mxnet-2019-12-09-08-07-37-389\"',\n",
       "  'sagemaker_program': '\"mnist.py\"',\n",
       "  'sagemaker_region': '\"us-west-2\"',\n",
       "  'sagemaker_submit_directory': '\"s3://sagemaker-us-west-2-453691756499/mxnet-2019-12-09-08-07-37-389/source/sourcedir.tar.gz\"'},\n",
       " 'AlgorithmSpecification': {'TrainingImage': '763104351884.dkr.ecr.us-west-2.amazonaws.com/mxnet-training:1.6.0-cpu-py3',\n",
       "  'TrainingInputMode': 'File',\n",
       "  'EnableSageMakerMetricsTimeSeries': True},\n",
       " 'RoleArn': 'arn:aws:iam::453691756499:role/service-role/AmazonSageMaker-ExecutionRole-20190820T113591',\n",
       " 'InputDataConfig': [],\n",
       " 'OutputDataConfig': {'KmsKeyId': '',\n",
       "  'S3OutputPath': 's3://sagemaker-us-west-2-453691756499/'},\n",
       " 'ResourceConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "  'InstanceCount': 1,\n",
       "  'VolumeSizeInGB': 400},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       " 'CreationTime': datetime.datetime(2019, 12, 9, 8, 7, 37, 990000, tzinfo=tzlocal()),\n",
       " 'TrainingStartTime': datetime.datetime(2019, 12, 9, 8, 9, 20, 381000, tzinfo=tzlocal()),\n",
       " 'TrainingEndTime': datetime.datetime(2019, 12, 9, 8, 10, 52, 118000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2019, 12, 9, 8, 10, 52, 118000, tzinfo=tzlocal()),\n",
       " 'SecondaryStatusTransitions': [{'Status': 'Starting',\n",
       "   'StartTime': datetime.datetime(2019, 12, 9, 8, 7, 37, 990000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2019, 12, 9, 8, 9, 20, 381000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Preparing the instances for training'},\n",
       "  {'Status': 'Downloading',\n",
       "   'StartTime': datetime.datetime(2019, 12, 9, 8, 9, 20, 381000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2019, 12, 9, 8, 9, 28, 876000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Downloading input data'},\n",
       "  {'Status': 'Training',\n",
       "   'StartTime': datetime.datetime(2019, 12, 9, 8, 9, 28, 876000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2019, 12, 9, 8, 10, 45, 585000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Training image download completed. Training in progress.'},\n",
       "  {'Status': 'Uploading',\n",
       "   'StartTime': datetime.datetime(2019, 12, 9, 8, 10, 45, 585000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2019, 12, 9, 8, 10, 52, 118000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Uploading generated training model'},\n",
       "  {'Status': 'Completed',\n",
       "   'StartTime': datetime.datetime(2019, 12, 9, 8, 10, 52, 118000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2019, 12, 9, 8, 10, 52, 118000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Training job completed'}],\n",
       " 'EnableNetworkIsolation': False,\n",
       " 'EnableInterContainerTrafficEncryption': False,\n",
       " 'EnableManagedSpotTraining': False,\n",
       " 'TrainingTimeInSeconds': 92,\n",
       " 'BillableTimeInSeconds': 92,\n",
       " 'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-us-west-2-453691756499/smdebug-mnist-tensor-analysis',\n",
       "  'CollectionConfigurations': [{'CollectionName': 'all',\n",
       "    'CollectionParameters': {'include_regex': '.*', 'save_interval': '100'}}]},\n",
       " 'ResponseMetadata': {'RequestId': '60df79b5-92df-4244-9117-293f14fdd558',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '60df79b5-92df-4244-9117-293f14fdd558',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '2664',\n",
       "   'date': 'Mon, 09 Dec 2019 08:13:14 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = estimator.latest_training_job.name\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=job_name)\n",
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the S3 location of the tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensors are stored in:  s3://sagemaker-us-west-2-453691756499/smdebug-mnist-tensor-analysis/mxnet-2019-12-09-08-07-37-389/debug-output\n"
     ]
    }
   ],
   "source": [
    "path = estimator.latest_job_debugger_artifacts_path()\n",
    "print('Tensors are stored in: ', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download tensors from S3\n",
    "\n",
    "Now we will download the tensors from S3, so that we can visualize them in our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tensors into folder:  /tmp/debug-output\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"/tmp/{}\".format(path.split(\"/\")[-1])\n",
    "os.system(\"aws s3 cp --recursive {} {}\".format(path,folder_name))\n",
    "print('Downloading tensors into folder: ', folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained the tensors from our training job, it is time to plot the distribution of different layers. \n",
    "In the following sections we will use Amazon SageMaker Debugger and custom rules to retrieve certain tensors. Typically, rules are supposed to return True or False. However in this notebook we will use custom rules to return dictionaries of aggregated tensors per layer and step, which we then plot afterwards.\n",
    "\n",
    "### Activation outputs\n",
    "This rule will use Amazon SageMaker Debugger to retrieve tensors from the ReLU output layers. It sums the activations across batch and steps. If there is a large fraction of ReLUs outputing 0 across many steps it means that the neuron is dying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.trials import create_trial\n",
    "from smdebug.rules.rule_invoker import invoke_rule\n",
    "from smdebug.exceptions import NoMoreData\n",
    "from smdebug.rules.rule import Rule\n",
    "import numpy as np\n",
    "import utils\n",
    "import collections\n",
    "import os\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-09 08:17:04.605 ip-172-16-62-40:11373 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n"
     ]
    }
   ],
   "source": [
    "trial = create_trial('/tmp/debug-output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-09 08:17:11.211 ip-172-16-62-40:11373 INFO trial.py:197] Training has ended, will refresh one final time in 1 sec.\n",
      "[2019-12-09 08:17:12.213 ip-172-16-62-40:11373 INFO trial.py:209] Loaded all steps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<smdebug.trials.local_trial.LocalTrial object at 0x7f2c1ef259b0>:(\n",
       "    name=debug-output,\n",
       "    path=/tmp/debug-output,\n",
       "    steps=[0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400],\n",
       "    collections=['weights', 'biases', 'gradients', 'losses', 'scalars', 'default', 'all'],\n",
       "    tensor_names=['conv0_bias', 'conv0_input_0', 'conv0_output_0', 'conv0_relu_input_0', 'conv0_relu_output_0', 'conv0_weight', 'conv1_bias', 'conv1_input_0', 'conv1_output_0', 'conv1_relu_input_0', 'conv1_relu_output_0', 'conv1_weight', 'dense0_bias', 'dense0_input_0', 'dense0_output_0', 'dense0_relu_input_0', 'dense0_relu_output_0', 'dense0_weight', 'dense1_bias', 'dense1_input_0', 'dense1_output_0', 'dense1_relu_input_0', 'dense1_relu_output_0', 'dense1_weight', 'dense2_bias', 'dense2_input_0', 'dense2_output_0', 'dense2_weight', 'flatten0_input_0', 'flatten0_output_0', 'gradient/conv0_bias', 'gradient/conv0_weight', 'gradient/conv1_bias', 'gradient/conv1_weight', 'gradient/dense0_bias', 'gradient/dense0_weight', 'gradient/dense1_bias', 'gradient/dense1_weight', 'gradient/dense2_bias', 'gradient/dense2_weight', 'hybridsequential0_input_0', 'hybridsequential0_output_0', 'pool0_input_0', 'pool0_output_0', 'pool1_input_0', 'pool1_output_0', 'softmaxcrossentropyloss0_input_0', 'softmaxcrossentropyloss0_input_1', 'softmaxcrossentropyloss0_output_0'],\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-09 08:17:44.288 ip-172-16-62-40:11373 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2019-12-09 08:17:44.301 ip-172-16-62-40:11373 INFO rule_invoker.py:10] Started execution of rule ActivationOutputs at step 0\n",
      "[2019-12-09 08:17:44.302 ip-172-16-62-40:11373 INFO trial.py:197] Training has ended, will refresh one final time in 1 sec.\n",
      "[2019-12-09 08:17:45.304 ip-172-16-62-40:11373 INFO trial.py:209] Loaded all steps\n",
      "[2019-12-09 08:17:45.319 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 0 tensor  conv0_relu_output_0  has 48.73792860243056% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.325 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 0 tensor  conv1_relu_output_0  has 51.16064453125% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.326 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 0 tensor  dense0_relu_output_0  has 53.26822916666667% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.328 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 0 tensor  dense1_relu_output_0  has 51.28348214285714% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.338 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 100 tensor  conv0_relu_output_0  has 53.13268590856482% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.347 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 100 tensor  conv1_relu_output_0  has 98.43359375% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.349 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 100 tensor  dense0_relu_output_0  has 53.990885416666664% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.351 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 100 tensor  dense1_relu_output_0  has 58.798363095238095% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.363 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 200 tensor  conv0_relu_output_0  has 50.73219581886575% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.372 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 200 tensor  conv1_relu_output_0  has 99.98681640625% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.375 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 200 tensor  dense0_relu_output_0  has 74.90234375% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.376 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 200 tensor  dense1_relu_output_0  has 65.90401785714286% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.389 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 300 tensor  conv0_relu_output_0  has 51.55097113715278% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.398 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 300 tensor  conv1_relu_output_0  has 99.99658203125% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.401 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 300 tensor  dense0_relu_output_0  has 77.1484375% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.402 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 300 tensor  dense1_relu_output_0  has 70.65662202380952% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.415 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 400 tensor  conv0_relu_output_0  has 53.84408456307871% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.421 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 400 tensor  conv1_relu_output_0  has 99.99755859375% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.423 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 400 tensor  dense0_relu_output_0  has 78.33984375% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.425 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 400 tensor  dense1_relu_output_0  has 75.5859375% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.437 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 500 tensor  conv0_relu_output_0  has 50.65737123842593% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.446 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 500 tensor  conv1_relu_output_0  has 99.9970703125% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.449 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 500 tensor  dense0_relu_output_0  has 77.87760416666667% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.450 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 500 tensor  dense1_relu_output_0  has 73.01897321428571% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.463 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 600 tensor  conv0_relu_output_0  has 51.412172670717595% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.472 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 600 tensor  conv1_relu_output_0  has 99.998046875% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.475 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 600 tensor  dense0_relu_output_0  has 79.8828125% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.476 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 600 tensor  dense1_relu_output_0  has 74.38616071428571% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.488 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 700 tensor  conv0_relu_output_0  has 51.279477719907405% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.497 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 700 tensor  conv1_relu_output_0  has 99.998046875% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.499 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 700 tensor  dense0_relu_output_0  has 79.93489583333333% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.501 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 700 tensor  dense1_relu_output_0  has 73.20498511904762% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.513 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 800 tensor  conv0_relu_output_0  has 51.72571252893518% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.522 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 800 tensor  conv1_relu_output_0  has 99.99853515625% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.524 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 800 tensor  dense0_relu_output_0  has 79.60286458333333% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.526 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 800 tensor  dense1_relu_output_0  has 75.93005952380952% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.538 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 900 tensor  conv0_relu_output_0  has 49.91387261284722% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.547 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 900 tensor  conv1_relu_output_0  has 99.99853515625% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.550 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 900 tensor  dense0_relu_output_0  has 78.58072916666666% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.551 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 900 tensor  dense1_relu_output_0  has 78.05989583333334% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.563 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1000 tensor  conv0_relu_output_0  has 51.46981698495371% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.573 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1000 tensor  conv1_relu_output_0  has 99.99853515625% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.575 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1000 tensor  dense0_relu_output_0  has 78.671875% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.576 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1000 tensor  dense1_relu_output_0  has 78.08779761904762% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.588 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1100 tensor  conv0_relu_output_0  has 52.73595739293982% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.597 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1100 tensor  conv1_relu_output_0  has 100.0% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.600 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1100 tensor  dense0_relu_output_0  has 80.0% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.601 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1100 tensor  dense1_relu_output_0  has 79.76190476190477% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.613 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1200 tensor  conv0_relu_output_0  has 53.250009042245374% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.622 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1200 tensor  conv1_relu_output_0  has 99.998046875% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.625 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1200 tensor  dense0_relu_output_0  has 78.3203125% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.626 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1200 tensor  dense1_relu_output_0  has 77.83668154761905% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.638 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1300 tensor  conv0_relu_output_0  has 53.280752676504626% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.647 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1300 tensor  conv1_relu_output_0  has 99.99951171875% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.649 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1300 tensor  dense0_relu_output_0  has 80.60546875% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.651 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1300 tensor  dense1_relu_output_0  has 80.80357142857143% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.662 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1400 tensor  conv0_relu_output_0  has 52.19048394097222% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.671 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1400 tensor  conv1_relu_output_0  has 99.99951171875% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.673 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1400 tensor  dense0_relu_output_0  has 81.4453125% activation outputs which are smaller than 0 \n",
      "[2019-12-09 08:17:45.675 ip-172-16-62-40:11373 INFO <ipython-input-21-c7f9e2eb0647>:17]  Step 1400 tensor  dense1_relu_output_0  has 80.82217261904762% activation outputs which are smaller than 0 \n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    }
   ],
   "source": [
    "class ActivationOutputs(Rule):\n",
    "    def __init__(self, base_trial):\n",
    "        super().__init__(base_trial)  \n",
    "        self.tensors = collections.OrderedDict() \n",
    "    \n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex='.*relu_output'):\n",
    "            if \"gradients\" not in tname:\n",
    "                try:\n",
    "                    tensor = self.base_trial.tensor(tname).value(step)\n",
    "                    if tname not in self.tensors:\n",
    "                        self.tensors[tname] = collections.OrderedDict()\n",
    "                    if step not in self.tensors[tname]:\n",
    "                        self.tensors[tname][step] = 0\n",
    "                    neg_values = np.where(tensor <= 0)[0]\n",
    "                    if len(neg_values) > 0:\n",
    "                        self.logger.info(f\" Step {step} tensor  {tname}  has {len(neg_values)/tensor.size*100}% activation outputs which are smaller than 0 \")\n",
    "                    batch_over_sum = np.sum(tensor, axis=0)/tensor.shape[0]\n",
    "                    self.tensors[tname][step] += batch_over_sum\n",
    "                except:\n",
    "                    self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = ActivationOutputs(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print('The training has ended and there is no more data to be analyzed. This is expected behavior.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(rule.tensors, filename='images/activation_outputs.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/activation_outputs.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='images/activation_outputs.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Inputs\n",
    "In this rule we look at the inputs into activation function, rather than the output. This can be helpful to understand if there are extreme negative or positive values that saturate the activation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-09 08:19:08.848 ip-172-16-62-40:11373 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2019-12-09 08:19:08.861 ip-172-16-62-40:11373 INFO rule_invoker.py:10] Started execution of rule ActivationInputs at step 0\n",
      "[2019-12-09 08:19:08.862 ip-172-16-62-40:11373 INFO trial.py:197] Training has ended, will refresh one final time in 1 sec.\n",
      "[2019-12-09 08:19:09.864 ip-172-16-62-40:11373 INFO trial.py:209] Loaded all steps\n",
      "[2019-12-09 08:19:09.871 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 48.73792860243056% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.875 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 51.16064453125% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.877 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 53.26822916666667% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.879 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 51.28348214285714% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.888 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 53.13268590856482% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.894 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 98.43359375% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.897 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 53.990885416666664% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.898 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 58.798363095238095% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.910 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 50.73219581886575% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.918 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.98681640625% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.919 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 74.90234375% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.921 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 65.90401785714286% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.934 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 51.55097113715278% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.938 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99658203125% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.940 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 77.1484375% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.941 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 70.65662202380952% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.954 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 53.84408456307871% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.959 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99755859375% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.960 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 78.33984375% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.962 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 75.5859375% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.970 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 50.65737123842593% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.976 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.9970703125% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.978 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 77.87760416666667% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.979 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 73.01897321428571% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.987 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 51.412172670717595% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.990 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.998046875% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.992 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 79.8828125% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:09.993 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 74.38616071428571% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.000 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 51.279477719907405% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.004 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.998046875% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.005 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 79.93489583333333% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.006 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 73.20498511904762% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.014 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 51.72571252893518% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.018 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99853515625% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.019 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 79.60286458333333% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.020 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 75.93005952380952% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.027 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 49.91387261284722% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.031 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99853515625% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.032 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 78.58072916666666% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.034 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 78.05989583333334% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.041 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 51.46981698495371% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.045 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99853515625% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.046 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 78.671875% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.048 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 78.08779761904762% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.055 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 52.73595739293982% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.059 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 100.0% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.061 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 80.0% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.062 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 79.76190476190477% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.069 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 53.250009042245374% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.073 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.998046875% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.074 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 78.3203125% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.076 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 77.83668154761905% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.084 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 53.280752676504626% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.087 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99951171875% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.089 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 80.60546875% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.090 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 80.80357142857143% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.098 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 52.19048394097222% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.102 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99951171875% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.103 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 81.4453125% activation inputs which are smaller than 0 \n",
      "[2019-12-09 08:19:10.104 ip-172-16-62-40:11373 INFO <ipython-input-25-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 80.82217261904762% activation inputs which are smaller than 0 \n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    }
   ],
   "source": [
    "class ActivationInputs(Rule):\n",
    "    def __init__(self, base_trial):\n",
    "        super().__init__(base_trial)  \n",
    "        self.tensors = collections.OrderedDict() \n",
    "        \n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex='.*relu_input'):\n",
    "            if \"gradients\" not in tname:\n",
    "                try:\n",
    "                    tensor = self.base_trial.tensor(tname).value(step)\n",
    "                    if tname not in self.tensors:\n",
    "                        self.tensors[tname] = {}\n",
    "                    if step not in self.tensors[tname]:\n",
    "                        self.tensors[tname][step] = 0\n",
    "                    neg_values = np.where(tensor <= 0)[0]\n",
    "                    if len(neg_values) > 0:\n",
    "                        self.logger.info(f\" Tensor  {tname}  has {len(neg_values)/tensor.size*100}% activation inputs which are smaller than 0 \")\n",
    "                    batch_over_sum = np.sum(tensor, axis=0)/tensor.shape[0]\n",
    "                    self.tensors[tname][step] += batch_over_sum\n",
    "                except:\n",
    "                    self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = ActivationInputs(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print('The training has ended and there is no more data to be analyzed. This is expected behavior.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(rule.tensors, filename='images/activation_inputs.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that second convolutional layer `conv1_relu_input_0` receives only negative input values, which means that all ReLUs in this layer output 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/activation_inputs.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='images/activation_inputs.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients\n",
    "The following code retrieves the gradients and plots their distribution. If variance is tiny, that means that the model parameters do not get updated effectively with each training step or that the training has converged to a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-09 08:21:08.745 ip-172-16-62-40:11373 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2019-12-09 08:21:08.756 ip-172-16-62-40:11373 INFO rule_invoker.py:10] Started execution of rule GradientsLayer at step 0\n",
      "[2019-12-09 08:21:08.758 ip-172-16-62-40:11373 INFO trial.py:197] Training has ended, will refresh one final time in 1 sec.\n",
      "[2019-12-09 08:21:09.759 ip-172-16-62-40:11373 INFO trial.py:209] Loaded all steps\n",
      "[2019-12-09 08:21:09.761 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -5419.91064453125 28531.94921875 \n",
      "[2019-12-09 08:21:09.762 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -13531.4794921875 40225.25390625 \n",
      "[2019-12-09 08:21:09.763 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -1851.815673828125 10187.85546875 \n",
      "[2019-12-09 08:21:09.764 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -11079.7001953125 38334.07421875 \n",
      "[2019-12-09 08:21:09.765 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -169.90017700195312 317.505859375 \n",
      "[2019-12-09 08:21:09.767 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -4382.1650390625 8710.158203125 \n",
      "[2019-12-09 08:21:09.768 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -96.2618179321289 81.03601837158203 \n",
      "[2019-12-09 08:21:09.770 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -20654.611328125 16830.671875 \n",
      "[2019-12-09 08:21:09.772 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -16.0 49.02497482299805 \n",
      "[2019-12-09 08:21:09.773 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -18266.5234375 50775.74609375 \n",
      "[2019-12-09 08:21:09.776 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -619.7899780273438 952.2459106445312 \n",
      "[2019-12-09 08:21:09.777 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -1089.8607177734375 1455.1658935546875 \n",
      "[2019-12-09 08:21:09.778 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -123.19869232177734 385.8603820800781 \n",
      "[2019-12-09 08:21:09.780 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -369.13470458984375 913.2953491210938 \n",
      "[2019-12-09 08:21:09.782 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -58.1231689453125 70.75948333740234 \n",
      "[2019-12-09 08:21:09.783 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -56.557029724121094 68.7027359008789 \n",
      "[2019-12-09 08:21:09.784 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -16.51622772216797 21.968795776367188 \n",
      "[2019-12-09 08:21:09.786 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -52.87275314331055 68.7800064086914 \n",
      "[2019-12-09 08:21:09.787 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -6.909756660461426 12.557209968566895 \n",
      "[2019-12-09 08:21:09.788 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -89.01004791259766 132.83963012695312 \n",
      "[2019-12-09 08:21:09.791 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -230.2766876220703 118.37548828125 \n",
      "[2019-12-09 08:21:09.793 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -170.62722778320312 127.15687561035156 \n",
      "[2019-12-09 08:21:09.794 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -3.113647937774658 21.36267852783203 \n",
      "[2019-12-09 08:21:09.795 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -22.21940803527832 81.18779754638672 \n",
      "[2019-12-09 08:21:09.797 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -45.15534210205078 37.21637725830078 \n",
      "[2019-12-09 08:21:09.799 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -16.840625762939453 19.918241500854492 \n",
      "[2019-12-09 08:21:09.800 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -13.745851516723633 15.342658996582031 \n",
      "[2019-12-09 08:21:09.801 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -5.353452205657959 6.799692630767822 \n",
      "[2019-12-09 08:21:09.803 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -5.785445690155029 7.59660005569458 \n",
      "[2019-12-09 08:21:09.804 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -26.749462127685547 23.450902938842773 \n",
      "[2019-12-09 08:21:09.806 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -116.13484191894531 111.52446746826172 \n",
      "[2019-12-09 08:21:09.808 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -125.35955047607422 124.93075561523438 \n",
      "[2019-12-09 08:21:09.809 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -5.688934803009033 25.154315948486328 \n",
      "[2019-12-09 08:21:09.811 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -31.93111228942871 130.66732788085938 \n",
      "[2019-12-09 08:21:09.812 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -26.177671432495117 15.873894691467285 \n",
      "[2019-12-09 08:21:09.814 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -11.94929313659668 15.88316535949707 \n",
      "[2019-12-09 08:21:09.815 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -9.012773513793945 10.893099784851074 \n",
      "[2019-12-09 08:21:09.816 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -3.1108310222625732 2.9418625831604004 \n",
      "[2019-12-09 08:21:09.818 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -5.005707263946533 3.2189226150512695 \n",
      "[2019-12-09 08:21:09.820 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -12.223301887512207 12.141176223754883 \n",
      "[2019-12-09 08:21:09.823 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -40.381961822509766 28.218074798583984 \n",
      "[2019-12-09 08:21:09.824 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -35.92192077636719 46.66291046142578 \n",
      "[2019-12-09 08:21:09.825 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -2.857983350753784 12.307454109191895 \n",
      "[2019-12-09 08:21:09.826 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -14.339751243591309 51.168975830078125 \n",
      "[2019-12-09 08:21:09.827 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -20.362701416015625 27.00465202331543 \n",
      "[2019-12-09 08:21:09.830 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -4.192559719085693 2.8045034408569336 \n",
      "[2019-12-09 08:21:09.831 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -8.706352233886719 10.359232902526855 \n",
      "[2019-12-09 08:21:09.832 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -1.010689377784729 0.7992820143699646 \n",
      "[2019-12-09 08:21:09.833 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -4.170664310455322 6.085607528686523 \n",
      "[2019-12-09 08:21:09.835 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -4.437545299530029 2.6899619102478027 \n",
      "[2019-12-09 08:21:09.838 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -102.42334747314453 26.04149627685547 \n",
      "[2019-12-09 08:21:09.839 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -110.82608032226562 67.0199966430664 \n",
      "[2019-12-09 08:21:09.841 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: 0.0 21.151046752929688 \n",
      "[2019-12-09 08:21:09.842 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -0.0660630464553833 132.9935760498047 \n",
      "[2019-12-09 08:21:09.843 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -45.83613204956055 42.89281463623047 \n",
      "[2019-12-09 08:21:09.845 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -8.584393501281738 11.728067398071289 \n",
      "[2019-12-09 08:21:09.846 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -13.273934364318848 14.525101661682129 \n",
      "[2019-12-09 08:21:09.848 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -2.307464122772217 3.1032602787017822 \n",
      "[2019-12-09 08:21:09.849 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -5.886399269104004 8.785268783569336 \n",
      "[2019-12-09 08:21:09.850 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -14.982879638671875 13.935009956359863 \n",
      "[2019-12-09 08:21:09.852 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -26.75106430053711 7.663687705993652 \n",
      "[2019-12-09 08:21:09.854 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -34.01225280761719 17.71767234802246 \n",
      "[2019-12-09 08:21:09.855 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -0.4219973683357239 6.058173179626465 \n",
      "[2019-12-09 08:21:09.855 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -2.5429000854492188 27.078210830688477 \n",
      "[2019-12-09 08:21:09.856 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -26.721904754638672 22.046646118164062 \n",
      "[2019-12-09 08:21:09.858 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -11.728493690490723 12.151748657226562 \n",
      "[2019-12-09 08:21:09.859 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -9.483206748962402 6.68010139465332 \n",
      "[2019-12-09 08:21:09.860 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -3.248594284057617 3.1985952854156494 \n",
      "[2019-12-09 08:21:09.861 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -3.638124704360962 5.788681507110596 \n",
      "[2019-12-09 08:21:09.862 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -8.545909881591797 8.114988327026367 \n",
      "[2019-12-09 08:21:09.865 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -14.70453929901123 6.906400203704834 \n",
      "[2019-12-09 08:21:09.866 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -17.6414794921875 14.49886703491211 \n",
      "[2019-12-09 08:21:09.867 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -0.886550784111023 5.861663341522217 \n",
      "[2019-12-09 08:21:09.868 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -5.150352478027344 24.271671295166016 \n",
      "[2019-12-09 08:21:09.869 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -26.893213272094727 22.843265533447266 \n",
      "[2019-12-09 08:21:09.871 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -2.2059154510498047 2.614532947540283 \n",
      "[2019-12-09 08:21:09.872 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -8.6981201171875 8.680386543273926 \n",
      "[2019-12-09 08:21:09.873 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.5242146849632263 0.7493187785148621 \n",
      "[2019-12-09 08:21:09.874 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -6.032933712005615 6.724620342254639 \n",
      "[2019-12-09 08:21:09.875 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -1.987326979637146 2.073640823364258 \n",
      "[2019-12-09 08:21:09.877 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -76.2238998413086 13.099554061889648 \n",
      "[2019-12-09 08:21:09.879 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -57.026580810546875 58.23096466064453 \n",
      "[2019-12-09 08:21:09.880 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -2.2512059211730957 20.437557220458984 \n",
      "[2019-12-09 08:21:09.881 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -7.453258991241455 64.27210235595703 \n",
      "[2019-12-09 08:21:09.882 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -32.72881317138672 32.484779357910156 \n",
      "[2019-12-09 08:21:09.883 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -1.6653598546981812 1.1288830041885376 \n",
      "[2019-12-09 08:21:09.884 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -9.109240531921387 14.285587310791016 \n",
      "[2019-12-09 08:21:09.885 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.2792317271232605 0.5508030652999878 \n",
      "[2019-12-09 08:21:09.886 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -6.265506744384766 3.109464645385742 \n",
      "[2019-12-09 08:21:09.888 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -2.494473934173584 1.36796236038208 \n",
      "[2019-12-09 08:21:09.890 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -3.6035807132720947 7.508444786071777 \n",
      "[2019-12-09 08:21:09.891 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -11.24195384979248 13.630844116210938 \n",
      "[2019-12-09 08:21:09.892 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -3.581883668899536 1.5288519859313965 \n",
      "[2019-12-09 08:21:09.893 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -15.275867462158203 5.547348976135254 \n",
      "[2019-12-09 08:21:09.894 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -17.83000946044922 15.601850509643555 \n",
      "[2019-12-09 08:21:09.896 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -0.42886483669281006 0.47006216645240784 \n",
      "[2019-12-09 08:21:09.897 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -5.808843612670898 6.906661033630371 \n",
      "[2019-12-09 08:21:09.898 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.13246123492717743 0.15909507870674133 \n",
      "[2019-12-09 08:21:09.899 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -4.188987731933594 5.074189186096191 \n",
      "[2019-12-09 08:21:09.900 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -0.8445956707000732 0.4353567361831665 \n",
      "[2019-12-09 08:21:09.902 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -10.116043090820312 12.547447204589844 \n",
      "[2019-12-09 08:21:09.903 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -28.30362892150879 34.89521789550781 \n",
      "[2019-12-09 08:21:09.904 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -5.944496154785156 5.505586624145508 \n",
      "[2019-12-09 08:21:09.905 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -26.5928897857666 21.78630256652832 \n",
      "[2019-12-09 08:21:09.906 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -14.18310832977295 17.907114028930664 \n",
      "[2019-12-09 08:21:09.908 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -11.45322036743164 6.239177227020264 \n",
      "[2019-12-09 08:21:09.909 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -11.486647605895996 5.056596755981445 \n",
      "[2019-12-09 08:21:09.910 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -1.532616376876831 1.7802622318267822 \n",
      "[2019-12-09 08:21:09.911 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -4.921484470367432 4.46536922454834 \n",
      "[2019-12-09 08:21:09.912 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -8.793917655944824 4.657663345336914 \n",
      "[2019-12-09 08:21:09.915 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: 0.0 0.0 \n",
      "[2019-12-09 08:21:09.916 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: 0.0 0.0 \n",
      "[2019-12-09 08:21:09.917 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: 0.0 0.0 \n",
      "[2019-12-09 08:21:09.918 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: 0.0 0.0 \n",
      "[2019-12-09 08:21:09.919 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -40.20349884033203 44.95497512817383 \n",
      "[2019-12-09 08:21:09.921 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: 0.0 0.0 \n",
      "[2019-12-09 08:21:09.922 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -15.254594802856445 18.09235191345215 \n",
      "[2019-12-09 08:21:09.923 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.2849566638469696 0.3379657566547394 \n",
      "[2019-12-09 08:21:09.924 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -6.903934001922607 6.848443031311035 \n",
      "[2019-12-09 08:21:09.925 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -0.22097504138946533 0.21919876337051392 \n",
      "[2019-12-09 08:21:09.927 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -50.507755279541016 12.374672889709473 \n",
      "[2019-12-09 08:21:09.928 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -67.13799285888672 91.7853012084961 \n",
      "[2019-12-09 08:21:09.929 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -4.590726852416992 18.61356544494629 \n",
      "[2019-12-09 08:21:09.931 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -20.485044479370117 95.57981872558594 \n",
      "[2019-12-09 08:21:09.932 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -30.892915725708008 33.882843017578125 \n",
      "[2019-12-09 08:21:09.933 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -2.4410624504089355 3.1623425483703613 \n",
      "[2019-12-09 08:21:09.934 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -18.56124496459961 12.136738777160645 \n",
      "[2019-12-09 08:21:09.935 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.7966566681861877 0.9504133462905884 \n",
      "[2019-12-09 08:21:09.936 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -6.708583354949951 5.814645290374756 \n",
      "[2019-12-09 08:21:09.937 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -4.471829891204834 2.165736198425293 \n",
      "[2019-12-09 08:21:09.940 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -4.462854385375977 4.081392765045166 \n",
      "[2019-12-09 08:21:09.941 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -7.287933349609375 6.280696868896484 \n",
      "[2019-12-09 08:21:09.942 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -3.34403920173645 0.0 \n",
      "[2019-12-09 08:21:09.943 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -16.41217613220215 0.0 \n",
      "[2019-12-09 08:21:09.944 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -19.186359405517578 17.48263931274414 \n",
      "[2019-12-09 08:21:09.946 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -0.19469287991523743 0.22757059335708618 \n",
      "[2019-12-09 08:21:09.947 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -3.2311201095581055 6.7023115158081055 \n",
      "[2019-12-09 08:21:09.948 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.0628763884305954 0.11752080172300339 \n",
      "[2019-12-09 08:21:09.950 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -4.267817497253418 3.9096763134002686 \n",
      "[2019-12-09 08:21:09.951 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -0.26184001564979553 0.11045878380537033 \n",
      "[2019-12-09 08:21:09.953 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -11.04971694946289 12.314702033996582 \n",
      "[2019-12-09 08:21:09.954 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -15.226486206054688 13.376504898071289 \n",
      "[2019-12-09 08:21:09.956 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -3.4230589866638184 0.0 \n",
      "[2019-12-09 08:21:09.957 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -18.061851501464844 0.0 \n",
      "[2019-12-09 08:21:09.959 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -23.001131057739258 20.852798461914062 \n",
      "[2019-12-09 08:21:09.961 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -0.5826671123504639 0.33136388659477234 \n",
      "[2019-12-09 08:21:09.962 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -7.899825096130371 7.374726295471191 \n",
      "[2019-12-09 08:21:09.964 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.18494302034378052 0.16493064165115356 \n",
      "[2019-12-09 08:21:09.965 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -4.337947368621826 2.8950326442718506 \n",
      "[2019-12-09 08:21:09.967 ip-172-16-62-40:11373 INFO <ipython-input-29-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -0.5323882699012756 0.12941519916057587 \n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    }
   ],
   "source": [
    "class GradientsLayer(Rule):\n",
    "    def __init__(self, base_trial):\n",
    "        super().__init__(base_trial)  \n",
    "        self.tensors = collections.OrderedDict()  \n",
    "        \n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex='.*gradient'):\n",
    "            try:\n",
    "                tensor = self.base_trial.tensor(tname).value(step)\n",
    "                if tname not in self.tensors:\n",
    "                    self.tensors[tname] = {}\n",
    "\n",
    "                self.logger.info(f\" Tensor  {tname}  has gradients range: {np.min(tensor)} {np.max(tensor)} \")\n",
    "                self.tensors[tname][step] = tensor\n",
    "            except:\n",
    "                self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = GradientsLayer(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print('The training has ended and there is no more data to be analyzed. This is expected behavior.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(rule.tensors, filename='images/gradients.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/gradients.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='images/gradients.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check variance across layers\n",
    "The rule retrieves gradients, but this time we compare variance of gradient distribution across layers. We want to identify if there is a large difference between the min and max variance per training step. For instance, very deep neural networks may suffer from vanishing gradients the deeper we go. By checking this ratio we can determine if we run into such a situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-09 08:23:36.777 ip-172-16-62-40:11373 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2019-12-09 08:23:36.788 ip-172-16-62-40:11373 INFO rule_invoker.py:10] Started execution of rule GradientsAcrossLayers at step 0\n",
      "[2019-12-09 08:23:36.790 ip-172-16-62-40:11373 INFO trial.py:197] Training has ended, will refresh one final time in 1 sec.\n",
      "[2019-12-09 08:23:37.792 ip-172-16-62-40:11373 INFO trial.py:209] Loaded all steps\n",
      "[2019-12-09 08:23:37.793 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 0 current ratio: 120216512.0 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.794 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 0 current ratio: 120216512.0 156414736.0 Ratio: 1.3011085987091064\n",
      "[2019-12-09 08:23:37.797 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 0 current ratio: 7661114.5 156414736.0 Ratio: 20.41670799255371\n",
      "[2019-12-09 08:23:37.799 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 0 current ratio: 7661114.5 156414736.0 Ratio: 20.41670799255371\n",
      "[2019-12-09 08:23:37.801 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 0 current ratio: 7833.5732421875 156414736.0 Ratio: 19967.2265625\n",
      "[2019-12-09 08:23:37.803 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 0 current ratio: 7833.5732421875 156414736.0 Ratio: 19967.2265625\n",
      "[2019-12-09 08:23:37.805 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 0 current ratio: 835.0178833007812 156414736.0 Ratio: 187319.03125\n",
      "[2019-12-09 08:23:37.806 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 0 current ratio: 835.0178833007812 156414736.0 Ratio: 187319.03125\n",
      "[2019-12-09 08:23:37.808 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 0 current ratio: 570.01513671875 156414736.0 Ratio: 274404.53125\n",
      "[2019-12-09 08:23:37.810 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 0 current ratio: 570.01513671875 156414736.0 Ratio: 274404.53125\n",
      "[2019-12-09 08:23:37.813 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 100 current ratio: 262845.84375 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.814 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 100 current ratio: 252397.171875 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.815 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 100 current ratio: 14113.3134765625 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.816 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 100 current ratio: 14113.3134765625 21529.384765625 Ratio: 1.5254663228988647\n",
      "[2019-12-09 08:23:37.818 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 100 current ratio: 541.4047241210938 21529.384765625 Ratio: 39.765785217285156\n",
      "[2019-12-09 08:23:37.819 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 100 current ratio: 19.16611671447754 21529.384765625 Ratio: 1123.304443359375\n",
      "[2019-12-09 08:23:37.821 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 100 current ratio: 19.16611671447754 21529.384765625 Ratio: 1123.304443359375\n",
      "[2019-12-09 08:23:37.822 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 100 current ratio: 19.16611671447754 21529.384765625 Ratio: 1123.304443359375\n",
      "[2019-12-09 08:23:37.823 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 100 current ratio: 19.16611671447754 21529.384765625 Ratio: 1123.304443359375\n",
      "[2019-12-09 08:23:37.824 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 100 current ratio: 19.16611671447754 21529.384765625 Ratio: 1123.304443359375\n",
      "[2019-12-09 08:23:37.826 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 200 current ratio: 10661.841796875 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.827 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 200 current ratio: 2232.421630859375 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.829 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 200 current ratio: 60.30931091308594 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.830 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 200 current ratio: 60.30931091308594 215.9723663330078 Ratio: 3.581078290939331\n",
      "[2019-12-09 08:23:37.831 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 200 current ratio: 60.30931091308594 215.9723663330078 Ratio: 3.581078290939331\n",
      "[2019-12-09 08:23:37.833 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 200 current ratio: 0.28520312905311584 215.9723663330078 Ratio: 757.258056640625\n",
      "[2019-12-09 08:23:37.834 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 200 current ratio: 0.28520312905311584 215.9723663330078 Ratio: 757.258056640625\n",
      "[2019-12-09 08:23:37.835 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 200 current ratio: 0.28520312905311584 215.9723663330078 Ratio: 757.258056640625\n",
      "[2019-12-09 08:23:37.836 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 200 current ratio: 0.28520312905311584 215.9723663330078 Ratio: 757.258056640625\n",
      "[2019-12-09 08:23:37.837 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 200 current ratio: 0.28520312905311584 215.9723663330078 Ratio: 757.258056640625\n",
      "[2019-12-09 08:23:37.839 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 300 current ratio: 6107.89501953125 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.840 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 300 current ratio: 2310.324951171875 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.841 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 300 current ratio: 64.78929138183594 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.842 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 300 current ratio: 64.78929138183594 164.88522338867188 Ratio: 2.54494571685791\n",
      "[2019-12-09 08:23:37.843 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 300 current ratio: 46.15591812133789 164.88522338867188 Ratio: 3.572352886199951\n",
      "[2019-12-09 08:23:37.846 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 300 current ratio: 0.04627033323049545 164.88522338867188 Ratio: 3563.519287109375\n",
      "[2019-12-09 08:23:37.847 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 300 current ratio: 0.04627033323049545 164.88522338867188 Ratio: 3563.519287109375\n",
      "[2019-12-09 08:23:37.848 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 300 current ratio: 0.04627033323049545 164.88522338867188 Ratio: 3563.519287109375\n",
      "[2019-12-09 08:23:37.849 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 300 current ratio: 0.04627033323049545 164.88522338867188 Ratio: 3563.519287109375\n",
      "[2019-12-09 08:23:37.850 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 300 current ratio: 0.04627033323049545 164.88522338867188 Ratio: 3563.519287109375\n",
      "[2019-12-09 08:23:37.853 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 400 current ratio: 425.0735168457031 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.854 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 400 current ratio: 310.4525146484375 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.855 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 400 current ratio: 9.646875381469727 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.856 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 400 current ratio: 9.646875381469727 30.631254196166992 Ratio: 3.1752512454986572\n",
      "[2019-12-09 08:23:37.858 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 400 current ratio: 9.646875381469727 32.361419677734375 Ratio: 3.3546011447906494\n",
      "[2019-12-09 08:23:37.859 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 400 current ratio: 0.003483819542452693 32.361419677734375 Ratio: 9289.0634765625\n",
      "[2019-12-09 08:23:37.860 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 400 current ratio: 0.003483819542452693 32.361419677734375 Ratio: 9289.0634765625\n",
      "[2019-12-09 08:23:37.861 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 400 current ratio: 0.003483819542452693 32.361419677734375 Ratio: 9289.0634765625\n",
      "[2019-12-09 08:23:37.862 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 400 current ratio: 0.003483819542452693 32.361419677734375 Ratio: 9289.0634765625\n",
      "[2019-12-09 08:23:37.864 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 400 current ratio: 0.003483819542452693 32.361419677734375 Ratio: 9289.0634765625\n",
      "[2019-12-09 08:23:37.866 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 500 current ratio: 1974.7744140625 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.867 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 500 current ratio: 1229.5162353515625 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.868 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 500 current ratio: 45.446815490722656 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.869 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 500 current ratio: 45.446815490722656 152.30320739746094 Ratio: 3.351240396499634\n",
      "[2019-12-09 08:23:37.870 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 500 current ratio: 45.446815490722656 152.30320739746094 Ratio: 3.351240396499634\n",
      "[2019-12-09 08:23:37.872 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 500 current ratio: 0.03240059316158295 152.30320739746094 Ratio: 4700.63037109375\n",
      "[2019-12-09 08:23:37.873 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 500 current ratio: 0.03240059316158295 152.30320739746094 Ratio: 4700.63037109375\n",
      "[2019-12-09 08:23:37.876 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 500 current ratio: 0.03240059316158295 152.30320739746094 Ratio: 4700.63037109375\n",
      "[2019-12-09 08:23:37.877 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 500 current ratio: 0.03240059316158295 152.30320739746094 Ratio: 4700.63037109375\n",
      "[2019-12-09 08:23:37.878 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 500 current ratio: 0.03240059316158295 152.30320739746094 Ratio: 4700.63037109375\n",
      "[2019-12-09 08:23:37.881 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 600 current ratio: 142.01792907714844 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.883 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 600 current ratio: 88.69595336914062 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.884 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 600 current ratio: 3.308682441711426 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.886 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 600 current ratio: 3.308682441711426 9.136823654174805 Ratio: 2.7614688873291016\n",
      "[2019-12-09 08:23:37.887 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 600 current ratio: 3.308682441711426 41.118534088134766 Ratio: 12.427464485168457\n",
      "[2019-12-09 08:23:37.889 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 600 current ratio: 0.030220622196793556 41.118534088134766 Ratio: 1360.61181640625\n",
      "[2019-12-09 08:23:37.890 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 600 current ratio: 0.030220622196793556 41.118534088134766 Ratio: 1360.61181640625\n",
      "[2019-12-09 08:23:37.891 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 600 current ratio: 0.030220622196793556 41.118534088134766 Ratio: 1360.61181640625\n",
      "[2019-12-09 08:23:37.893 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 600 current ratio: 0.030220622196793556 41.118534088134766 Ratio: 1360.61181640625\n",
      "[2019-12-09 08:23:37.894 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 600 current ratio: 0.030220622196793556 41.118534088134766 Ratio: 1360.61181640625\n",
      "[2019-12-09 08:23:37.897 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 700 current ratio: 59.02883529663086 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.898 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 700 current ratio: 46.57844543457031 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.900 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 700 current ratio: 2.2389976978302 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.901 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 700 current ratio: 2.2389976978302 4.898462295532227 Ratio: 2.1877925395965576\n",
      "[2019-12-09 08:23:37.903 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 700 current ratio: 2.2389976978302 40.22215270996094 Ratio: 17.964357376098633\n",
      "[2019-12-09 08:23:37.905 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 700 current ratio: 0.0027776043862104416 40.22215270996094 Ratio: 14480.87890625\n",
      "[2019-12-09 08:23:37.907 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 700 current ratio: 0.0027776043862104416 40.22215270996094 Ratio: 14480.87890625\n",
      "[2019-12-09 08:23:37.908 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 700 current ratio: 0.0027776043862104416 40.22215270996094 Ratio: 14480.87890625\n",
      "[2019-12-09 08:23:37.909 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 700 current ratio: 0.0027776043862104416 40.22215270996094 Ratio: 14480.87890625\n",
      "[2019-12-09 08:23:37.910 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 700 current ratio: 0.0027776043862104416 40.22215270996094 Ratio: 14480.87890625\n",
      "[2019-12-09 08:23:37.913 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 800 current ratio: 857.391357421875 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.914 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 800 current ratio: 465.2253112792969 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.915 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 800 current ratio: 25.130640029907227 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.916 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 800 current ratio: 25.130640029907227 47.30439758300781 Ratio: 1.882339596748352\n",
      "[2019-12-09 08:23:37.917 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 800 current ratio: 25.130640029907227 60.11104965209961 Ratio: 2.3919427394866943\n",
      "[2019-12-09 08:23:37.919 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 800 current ratio: 0.0004990436136722565 60.11104965209961 Ratio: 120452.5\n",
      "[2019-12-09 08:23:37.920 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 800 current ratio: 0.0004990436136722565 60.11104965209961 Ratio: 120452.5\n",
      "[2019-12-09 08:23:37.921 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 800 current ratio: 0.0004990436136722565 60.11104965209961 Ratio: 120452.5\n",
      "[2019-12-09 08:23:37.923 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 800 current ratio: 0.0004990436136722565 60.11104965209961 Ratio: 120452.5\n",
      "[2019-12-09 08:23:37.924 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 800 current ratio: 0.0004990436136722565 60.11104965209961 Ratio: 120452.5\n",
      "[2019-12-09 08:23:37.926 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 900 current ratio: 15.086639404296875 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.927 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 900 current ratio: 15.086639404296875 20.536386489868164 Ratio: 1.3612300157546997\n",
      "[2019-12-09 08:23:37.928 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 900 current ratio: 0.933872401714325 20.536386489868164 Ratio: 21.990570068359375\n",
      "[2019-12-09 08:23:37.930 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 900 current ratio: 0.933872401714325 20.536386489868164 Ratio: 21.990570068359375\n",
      "[2019-12-09 08:23:37.931 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 900 current ratio: 0.933872401714325 20.536386489868164 Ratio: 21.990570068359375\n",
      "[2019-12-09 08:23:37.932 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 900 current ratio: 7.589118467876688e-05 20.536386489868164 Ratio: 270603.0625\n",
      "[2019-12-09 08:23:37.933 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 900 current ratio: 7.589118467876688e-05 20.536386489868164 Ratio: 270603.0625\n",
      "[2019-12-09 08:23:37.934 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 900 current ratio: 7.589118467876688e-05 20.536386489868164 Ratio: 270603.0625\n",
      "[2019-12-09 08:23:37.935 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 900 current ratio: 7.589118467876688e-05 20.536386489868164 Ratio: 270603.0625\n",
      "[2019-12-09 08:23:37.937 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 900 current ratio: 7.589118467876688e-05 20.536386489868164 Ratio: 270603.0625\n",
      "[2019-12-09 08:23:37.939 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1000 current ratio: 65.12454223632812 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.941 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1000 current ratio: 65.12454223632812 116.92578125 Ratio: 1.7954181432724\n",
      "[2019-12-09 08:23:37.941 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1000 current ratio: 4.119680404663086 116.92578125 Ratio: 28.382246017456055\n",
      "[2019-12-09 08:23:37.943 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1000 current ratio: 4.119680404663086 116.92578125 Ratio: 28.382246017456055\n",
      "[2019-12-09 08:23:37.944 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1000 current ratio: 4.119680404663086 116.92578125 Ratio: 28.382246017456055\n",
      "[2019-12-09 08:23:37.945 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1000 current ratio: 0.012268313206732273 116.92578125 Ratio: 9530.7138671875\n",
      "[2019-12-09 08:23:37.946 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1000 current ratio: 0.012268313206732273 116.92578125 Ratio: 9530.7138671875\n",
      "[2019-12-09 08:23:37.947 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1000 current ratio: 0.012268313206732273 116.92578125 Ratio: 9530.7138671875\n",
      "[2019-12-09 08:23:37.948 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1000 current ratio: 0.012268313206732273 116.92578125 Ratio: 9530.7138671875\n",
      "[2019-12-09 08:23:37.950 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1000 current ratio: 0.012268313206732273 116.92578125 Ratio: 9530.7138671875\n",
      "[2019-12-09 08:23:37.954 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1100 current ratio: 0.0 0 Ratio: nan\n",
      "[2019-12-09 08:23:37.955 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1100 current ratio: 0.0 0 Ratio: nan\n",
      "[2019-12-09 08:23:37.956 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1100 current ratio: 0.0 0 Ratio: nan\n",
      "[2019-12-09 08:23:37.957 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1100 current ratio: 0.0 0 Ratio: nan\n",
      "[2019-12-09 08:23:37.958 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1100 current ratio: 0.0 87.67477416992188 Ratio: inf\n",
      "[2019-12-09 08:23:37.961 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1100 current ratio: 0.0 87.67477416992188 Ratio: inf\n",
      "[2019-12-09 08:23:37.962 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1100 current ratio: 0.0 87.67477416992188 Ratio: inf\n",
      "[2019-12-09 08:23:37.963 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1100 current ratio: 0.0 87.67477416992188 Ratio: inf\n",
      "[2019-12-09 08:23:37.964 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1100 current ratio: 0.0 87.67477416992188 Ratio: inf\n",
      "[2019-12-09 08:23:37.965 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1100 current ratio: 0.0 87.67477416992188 Ratio: inf\n",
      "[2019-12-09 08:23:37.970 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1200 current ratio: 503.2341613769531 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.971 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1200 current ratio: 503.2341613769531 596.1116943359375 Ratio: 1.1845612525939941\n",
      "[2019-12-09 08:23:37.972 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1200 current ratio: 24.069190979003906 596.1116943359375 Ratio: 24.766586303710938\n",
      "[2019-12-09 08:23:37.973 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1200 current ratio: 24.069190979003906 596.1116943359375 Ratio: 24.766586303710938\n",
      "[2019-12-09 08:23:37.974 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1200 current ratio: 24.069190979003906 596.1116943359375 Ratio: 24.766586303710938\n",
      "[2019-12-09 08:23:37.976 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1200 current ratio: 0.004436954390257597 596.1116943359375 Ratio: 134351.546875\n",
      "[2019-12-09 08:23:37.978 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1200 current ratio: 0.004436954390257597 596.1116943359375 Ratio: 134351.546875\n",
      "[2019-12-09 08:23:37.979 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1200 current ratio: 0.004436954390257597 596.1116943359375 Ratio: 134351.546875\n",
      "[2019-12-09 08:23:37.981 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1200 current ratio: 0.004436954390257597 596.1116943359375 Ratio: 134351.546875\n",
      "[2019-12-09 08:23:37.982 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1200 current ratio: 0.004436954390257597 596.1116943359375 Ratio: 134351.546875\n",
      "[2019-12-09 08:23:37.986 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1300 current ratio: 9.07251262664795 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.988 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1300 current ratio: 6.880722522735596 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.989 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1300 current ratio: 0.6552303433418274 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:37.991 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1300 current ratio: 0.6552303433418274 1.73148512840271 Ratio: 2.64255952835083\n",
      "[2019-12-09 08:23:37.992 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1300 current ratio: 0.6552303433418274 14.67824935913086 Ratio: 22.401662826538086\n",
      "[2019-12-09 08:23:37.994 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1300 current ratio: 1.0401058716524858e-05 14.67824935913086 Ratio: 1411226.5\n",
      "[2019-12-09 08:23:37.995 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1300 current ratio: 1.0401058716524858e-05 14.67824935913086 Ratio: 1411226.5\n",
      "[2019-12-09 08:23:37.998 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1300 current ratio: 1.0401058716524858e-05 14.67824935913086 Ratio: 1411226.5\n",
      "[2019-12-09 08:23:38.000 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1300 current ratio: 1.0401058716524858e-05 14.67824935913086 Ratio: 1411226.5\n",
      "[2019-12-09 08:23:38.001 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1300 current ratio: 1.0401058716524858e-05 14.67824935913086 Ratio: 1411226.5\n",
      "[2019-12-09 08:23:38.006 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1400 current ratio: 47.40013122558594 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:38.007 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1400 current ratio: 31.999805450439453 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:38.009 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1400 current ratio: 0.6865625381469727 0 Ratio: 0.0\n",
      "[2019-12-09 08:23:38.010 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1400 current ratio: 0.6865625381469727 3.2576358318328857 Ratio: 4.74484920501709\n",
      "[2019-12-09 08:23:38.011 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1400 current ratio: 0.6865625381469727 20.919689178466797 Ratio: 30.47018814086914\n",
      "[2019-12-09 08:23:38.014 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1400 current ratio: 3.926795398001559e-05 20.919689178466797 Ratio: 532742.0\n",
      "[2019-12-09 08:23:38.015 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1400 current ratio: 3.926795398001559e-05 20.919689178466797 Ratio: 532742.0\n",
      "[2019-12-09 08:23:38.017 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1400 current ratio: 3.926795398001559e-05 20.919689178466797 Ratio: 532742.0\n",
      "[2019-12-09 08:23:38.018 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1400 current ratio: 3.926795398001559e-05 20.919689178466797 Ratio: 532742.0\n",
      "[2019-12-09 08:23:38.019 ip-172-16-62-40:11373 INFO <ipython-input-32-0c18f883c3b5>:17]  Step 1400 current ratio: 3.926795398001559e-05 20.919689178466797 Ratio: 532742.0\n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:17: RuntimeWarning: divide by zero encountered in float_scalars\n"
     ]
    }
   ],
   "source": [
    "class GradientsAcrossLayers(Rule):\n",
    "    def __init__(self, base_trial, ):\n",
    "        super().__init__(base_trial)  \n",
    "        self.tensors = collections.OrderedDict()  \n",
    "        \n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex='.*gradient'):\n",
    "            try:\n",
    "                tensor = self.base_trial.tensor(tname).value(step)\n",
    "                if step not in self.tensors:\n",
    "                    self.tensors[step] = [np.inf, 0]\n",
    "                variance = np.var(tensor.flatten())\n",
    "                if variance < self.tensors[step][0]:\n",
    "                    self.tensors[step][0] = variance\n",
    "                elif variance > self.tensors[step][1]:\n",
    "                    self.tensors[step][1] = variance             \n",
    "                self.logger.info(f\" Step {step} current ratio: {self.tensors[step][0]} {self.tensors[step][1]} Ratio: {self.tensors[step][1] / self.tensors[step][0]}\") \n",
    "            except:\n",
    "                self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = GradientsAcrossLayers(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print('The training has ended and there is no more data to be analyzed. This is expected behavior.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check min and max values of the gradients across layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 variance of gradients:  570.01514  to  156414740.0\n",
      "Step 100 variance of gradients:  19.166117  to  21529.385\n",
      "Step 200 variance of gradients:  0.28520313  to  215.97237\n",
      "Step 300 variance of gradients:  0.046270333  to  164.88522\n",
      "Step 400 variance of gradients:  0.0034838195  to  32.36142\n",
      "Step 500 variance of gradients:  0.032400593  to  152.3032\n",
      "Step 600 variance of gradients:  0.030220622  to  41.118534\n",
      "Step 700 variance of gradients:  0.0027776044  to  40.222153\n",
      "Step 800 variance of gradients:  0.0004990436  to  60.11105\n",
      "Step 900 variance of gradients:  7.5891185e-05  to  20.536386\n",
      "Step 1000 variance of gradients:  0.012268313  to  116.92578\n",
      "Step 1100 variance of gradients:  0.0  to  87.674774\n",
      "Step 1200 variance of gradients:  0.0044369544  to  596.1117\n",
      "Step 1300 variance of gradients:  1.0401059e-05  to  14.678249\n",
      "Step 1400 variance of gradients:  3.9267954e-05  to  20.91969\n"
     ]
    }
   ],
   "source": [
    "for step in rule.tensors:\n",
    "    print(\"Step\", step, \"variance of gradients: \", rule.tensors[step][0], \" to \",  rule.tensors[step][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of weights\n",
    "This rule retrieves the weight tensors and checks the variance. If the distribution does not change much across steps it may indicate that the learning rate is too low, that gradients are too small or that the training has converged to a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-09 08:24:44.893 ip-172-16-62-40:11373 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2019-12-09 08:24:44.904 ip-172-16-62-40:11373 INFO rule_invoker.py:10] Started execution of rule WeightRatio at step 0\n",
      "[2019-12-09 08:24:44.906 ip-172-16-62-40:11373 INFO trial.py:197] Training has ended, will refresh one final time in 1 sec.\n",
      "[2019-12-09 08:24:45.908 ip-172-16-62-40:11373 INFO trial.py:209] Loaded all steps\n",
      "[2019-12-09 08:24:45.910 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.2831619679927826 \n",
      "[2019-12-09 08:24:45.911 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.33994680643081665 \n",
      "[2019-12-09 08:24:45.913 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33299320936203003 \n",
      "[2019-12-09 08:24:45.914 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33577877283096313 \n",
      "[2019-12-09 08:24:45.915 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3347977101802826 \n",
      "[2019-12-09 08:24:45.918 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.19157637655735016 \n",
      "[2019-12-09 08:24:45.919 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.31452256441116333 \n",
      "[2019-12-09 08:24:45.920 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33270254731178284 \n",
      "[2019-12-09 08:24:45.921 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.3343503773212433 \n",
      "[2019-12-09 08:24:45.923 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.31845512986183167 \n",
      "[2019-12-09 08:24:45.925 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.1805296391248703 \n",
      "[2019-12-09 08:24:45.926 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.3095983862876892 \n",
      "[2019-12-09 08:24:45.928 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33268555998802185 \n",
      "[2019-12-09 08:24:45.929 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33426517248153687 \n",
      "[2019-12-09 08:24:45.930 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.31750091910362244 \n",
      "[2019-12-09 08:24:45.933 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.17859669029712677 \n",
      "[2019-12-09 08:24:45.934 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.30871498584747314 \n",
      "[2019-12-09 08:24:45.936 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.332683801651001 \n",
      "[2019-12-09 08:24:45.937 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.3342564105987549 \n",
      "[2019-12-09 08:24:45.938 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.317402720451355 \n",
      "[2019-12-09 08:24:45.941 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.17756743729114532 \n",
      "[2019-12-09 08:24:45.942 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.30822181701660156 \n",
      "[2019-12-09 08:24:45.944 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.3326829671859741 \n",
      "[2019-12-09 08:24:45.945 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33425214886665344 \n",
      "[2019-12-09 08:24:45.946 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.31735488772392273 \n",
      "[2019-12-09 08:24:45.948 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.17694821953773499 \n",
      "[2019-12-09 08:24:45.950 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.3079189658164978 \n",
      "[2019-12-09 08:24:45.951 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33268240094184875 \n",
      "[2019-12-09 08:24:45.953 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33424943685531616 \n",
      "[2019-12-09 08:24:45.955 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3173243999481201 \n",
      "[2019-12-09 08:24:45.957 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.17652082443237305 \n",
      "[2019-12-09 08:24:45.959 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.3077107071876526 \n",
      "[2019-12-09 08:24:45.960 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.3326820135116577 \n",
      "[2019-12-09 08:24:45.961 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33424749970436096 \n",
      "[2019-12-09 08:24:45.962 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3173026740550995 \n",
      "[2019-12-09 08:24:45.965 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.1760725975036621 \n",
      "[2019-12-09 08:24:45.966 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.3075312077999115 \n",
      "[2019-12-09 08:24:45.968 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.3326817452907562 \n",
      "[2019-12-09 08:24:45.969 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33424603939056396 \n",
      "[2019-12-09 08:24:45.970 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.31728672981262207 \n",
      "[2019-12-09 08:24:45.973 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.17570248246192932 \n",
      "[2019-12-09 08:24:45.973 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.3073604106903076 \n",
      "[2019-12-09 08:24:45.975 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33268144726753235 \n",
      "[2019-12-09 08:24:45.976 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33424463868141174 \n",
      "[2019-12-09 08:24:45.978 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.31727105379104614 \n",
      "[2019-12-09 08:24:45.980 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.17543987929821014 \n",
      "[2019-12-09 08:24:45.981 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.30722466111183167 \n",
      "[2019-12-09 08:24:45.983 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33268123865127563 \n",
      "[2019-12-09 08:24:45.984 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33424344658851624 \n",
      "[2019-12-09 08:24:45.985 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.31725746393203735 \n",
      "[2019-12-09 08:24:45.988 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.1752040535211563 \n",
      "[2019-12-09 08:24:45.989 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.30711302161216736 \n",
      "[2019-12-09 08:24:45.990 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.3326810300350189 \n",
      "[2019-12-09 08:24:45.992 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33424243330955505 \n",
      "[2019-12-09 08:24:45.993 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.31724607944488525 \n",
      "[2019-12-09 08:24:45.995 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.17504478991031647 \n",
      "[2019-12-09 08:24:45.996 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.30702003836631775 \n",
      "[2019-12-09 08:24:45.998 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.332680881023407 \n",
      "[2019-12-09 08:24:45.999 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.334241658449173 \n",
      "[2019-12-09 08:24:46.001 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3172370493412018 \n",
      "[2019-12-09 08:24:46.003 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.17482727766036987 \n",
      "[2019-12-09 08:24:46.004 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.30693259835243225 \n",
      "[2019-12-09 08:24:46.006 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33268073201179504 \n",
      "[2019-12-09 08:24:46.007 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33424094319343567 \n",
      "[2019-12-09 08:24:46.008 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.31722912192344666 \n",
      "[2019-12-09 08:24:46.011 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.1745849847793579 \n",
      "[2019-12-09 08:24:46.012 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.306841105222702 \n",
      "[2019-12-09 08:24:46.013 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.3326805531978607 \n",
      "[2019-12-09 08:24:46.015 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.3342400789260864 \n",
      "[2019-12-09 08:24:46.016 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3172195553779602 \n",
      "[2019-12-09 08:24:46.018 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.1744697242975235 \n",
      "[2019-12-09 08:24:46.019 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.30678385496139526 \n",
      "[2019-12-09 08:24:46.021 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33268043398857117 \n",
      "[2019-12-09 08:24:46.022 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.3342396020889282 \n",
      "[2019-12-09 08:24:46.023 ip-172-16-62-40:11373 INFO <ipython-input-34-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3172142505645752 \n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    }
   ],
   "source": [
    "class WeightRatio(Rule):\n",
    "    def __init__(self, base_trial, ):\n",
    "        super().__init__(base_trial)  \n",
    "        self.tensors = collections.OrderedDict()  \n",
    "        \n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex='.*weight'):\n",
    "            if \"gradient\" not in tname:\n",
    "                try:\n",
    "                    tensor = self.base_trial.tensor(tname).value(step)\n",
    "                    if tname not in self.tensors:\n",
    "                        self.tensors[tname] = {}\n",
    "                 \n",
    "                    self.logger.info(f\" Tensor  {tname}  has weights with variance: {np.var(tensor.flatten())} \")\n",
    "                    self.tensors[tname][step] = tensor\n",
    "                except:\n",
    "                    self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = WeightRatio(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print('The training has ended and there is no more data to be analyzed. This is expected behavior.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(rule.tensors, filename='images/weights.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/weights.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='images/weights.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "\n",
    "This rule retrieves layer inputs excluding activation inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-09 08:26:34.086 ip-172-16-62-40:11373 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2019-12-09 08:26:34.097 ip-172-16-62-40:11373 INFO rule_invoker.py:10] Started execution of rule Inputs at step 0\n",
      "[2019-12-09 08:26:34.098 ip-172-16-62-40:11373 INFO trial.py:197] Training has ended, will refresh one final time in 1 sec.\n",
      "[2019-12-09 08:26:35.101 ip-172-16-62-40:11373 INFO trial.py:209] Loaded all steps\n",
      "[2019-12-09 08:26:35.407 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 0.9688668251037598 \n",
      "[2019-12-09 08:26:35.409 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 4.631735801696777 \n",
      "[2019-12-09 08:26:35.411 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 58.34519577026367 \n",
      "[2019-12-09 08:26:35.412 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 4567.81201171875 \n",
      "[2019-12-09 08:26:35.413 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 95591.2109375 \n",
      "[2019-12-09 08:26:35.415 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 58.34519577026367 \n",
      "[2019-12-09 08:26:35.417 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 0.9688668251037598 \n",
      "[2019-12-09 08:26:35.421 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 3.62184476852417 \n",
      "[2019-12-09 08:26:35.423 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 43.39231491088867 \n",
      "[2019-12-09 08:26:35.425 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 4557619.5 \n",
      "[2019-12-09 08:26:35.427 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 8.452880859375 \n",
      "[2019-12-09 08:26:35.432 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 0.9859987497329712 \n",
      "[2019-12-09 08:26:35.434 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.0086477994918823 \n",
      "[2019-12-09 08:26:35.436 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 0.05608796700835228 \n",
      "[2019-12-09 08:26:35.438 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 2.577444553375244 \n",
      "[2019-12-09 08:26:35.439 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 32.2889404296875 \n",
      "[2019-12-09 08:26:35.441 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 0.05608796700835228 \n",
      "[2019-12-09 08:26:35.444 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 0.9859987497329712 \n",
      "[2019-12-09 08:26:35.448 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 0.7227692604064941 \n",
      "[2019-12-09 08:26:35.450 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 0.016288643702864647 \n",
      "[2019-12-09 08:26:35.452 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 724.1642456054688 \n",
      "[2019-12-09 08:26:35.454 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 9.42181396484375 \n",
      "[2019-12-09 08:26:35.457 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.0320185422897339 \n",
      "[2019-12-09 08:26:35.459 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.2801284790039062 \n",
      "[2019-12-09 08:26:35.461 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 0.0006950494716875255 \n",
      "[2019-12-09 08:26:35.463 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.040474407374858856 \n",
      "[2019-12-09 08:26:35.465 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.7851430773735046 \n",
      "[2019-12-09 08:26:35.466 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 0.0006950494716875255 \n",
      "[2019-12-09 08:26:35.468 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.0320185422897339 \n",
      "[2019-12-09 08:26:35.473 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 0.9883172512054443 \n",
      "[2019-12-09 08:26:35.475 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 0.00017379701603204012 \n",
      "[2019-12-09 08:26:35.476 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 14.333717346191406 \n",
      "[2019-12-09 08:26:35.477 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 9.51995849609375 \n",
      "[2019-12-09 08:26:35.481 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 0.9960402846336365 \n",
      "[2019-12-09 08:26:35.484 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.3154237270355225 \n",
      "[2019-12-09 08:26:35.485 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 8.721276390133426e-05 \n",
      "[2019-12-09 08:26:35.487 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.0055632335133850574 \n",
      "[2019-12-09 08:26:35.489 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.07210429757833481 \n",
      "[2019-12-09 08:26:35.490 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 8.721276390133426e-05 \n",
      "[2019-12-09 08:26:35.492 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 0.9960402846336365 \n",
      "[2019-12-09 08:26:35.496 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.0273112058639526 \n",
      "[2019-12-09 08:26:35.499 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 2.1803927666042e-05 \n",
      "[2019-12-09 08:26:35.500 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 1.1936274766921997 \n",
      "[2019-12-09 08:26:35.502 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 8.1552734375 \n",
      "[2019-12-09 08:26:35.505 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.0618956089019775 \n",
      "[2019-12-09 08:26:35.507 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.485790729522705 \n",
      "[2019-12-09 08:26:35.509 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 1.7197140550706536e-05 \n",
      "[2019-12-09 08:26:35.511 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.0011113934451714158 \n",
      "[2019-12-09 08:26:35.512 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.01590985804796219 \n",
      "[2019-12-09 08:26:35.514 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 1.7197140550706536e-05 \n",
      "[2019-12-09 08:26:35.516 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.0618956089019775 \n",
      "[2019-12-09 08:26:35.520 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.1476784944534302 \n",
      "[2019-12-09 08:26:35.522 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 4.299523880035849e-06 \n",
      "[2019-12-09 08:26:35.524 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.3021492063999176 \n",
      "[2019-12-09 08:26:35.525 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.85833740234375 \n",
      "[2019-12-09 08:26:35.529 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 0.959142804145813 \n",
      "[2019-12-09 08:26:35.531 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.3866266012191772 \n",
      "[2019-12-09 08:26:35.533 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 9.179903281619772e-05 \n",
      "[2019-12-09 08:26:35.534 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.006315335631370544 \n",
      "[2019-12-09 08:26:35.536 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.11620697379112244 \n",
      "[2019-12-09 08:26:35.537 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 9.179903281619772e-05 \n",
      "[2019-12-09 08:26:35.539 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 0.959142804145813 \n",
      "[2019-12-09 08:26:35.544 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.0794696807861328 \n",
      "[2019-12-09 08:26:35.546 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 2.295121521456167e-05 \n",
      "[2019-12-09 08:26:35.547 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 2.9819247722625732 \n",
      "[2019-12-09 08:26:35.549 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.84375 \n",
      "[2019-12-09 08:26:35.553 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.044816493988037 \n",
      "[2019-12-09 08:26:35.555 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.4771150350570679 \n",
      "[2019-12-09 08:26:35.557 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 7.9017409007065e-05 \n",
      "[2019-12-09 08:26:35.558 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.00497449841350317 \n",
      "[2019-12-09 08:26:35.560 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.07216133177280426 \n",
      "[2019-12-09 08:26:35.562 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 7.9017409007065e-05 \n",
      "[2019-12-09 08:26:35.564 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.044816493988037 \n",
      "[2019-12-09 08:26:35.568 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.1618295907974243 \n",
      "[2019-12-09 08:26:35.571 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 1.9754832464968786e-05 \n",
      "[2019-12-09 08:26:35.572 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.9713736772537231 \n",
      "[2019-12-09 08:26:35.574 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.902099609375 \n",
      "[2019-12-09 08:26:35.578 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 0.9682042598724365 \n",
      "[2019-12-09 08:26:35.581 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.3983067274093628 \n",
      "[2019-12-09 08:26:35.583 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 1.0042845133284573e-05 \n",
      "[2019-12-09 08:26:35.584 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.0006167683750391006 \n",
      "[2019-12-09 08:26:35.586 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.007651651278138161 \n",
      "[2019-12-09 08:26:35.588 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 1.0042845133284573e-05 \n",
      "[2019-12-09 08:26:35.590 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 0.9682042598724365 \n",
      "[2019-12-09 08:26:35.596 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.1046311855316162 \n",
      "[2019-12-09 08:26:35.598 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 2.5108283807639964e-06 \n",
      "[2019-12-09 08:26:35.600 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.059586815536022186 \n",
      "[2019-12-09 08:26:35.601 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 8.03216552734375 \n",
      "[2019-12-09 08:26:35.605 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 0.9755210876464844 \n",
      "[2019-12-09 08:26:35.607 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.4355108737945557 \n",
      "[2019-12-09 08:26:35.609 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 3.2114867281052284e-06 \n",
      "[2019-12-09 08:26:35.610 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.00020764600776601583 \n",
      "[2019-12-09 08:26:35.612 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.0033855850342661142 \n",
      "[2019-12-09 08:26:35.613 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 3.2114867281052284e-06 \n",
      "[2019-12-09 08:26:35.615 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 0.9755210876464844 \n",
      "[2019-12-09 08:26:35.623 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.1302409172058105 \n",
      "[2019-12-09 08:26:35.625 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 8.028936235859874e-07 \n",
      "[2019-12-09 08:26:35.627 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.03743215650320053 \n",
      "[2019-12-09 08:26:35.628 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.515625 \n",
      "[2019-12-09 08:26:35.632 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 0.9657462239265442 \n",
      "[2019-12-09 08:26:35.634 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.4277024269104004 \n",
      "[2019-12-09 08:26:35.636 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 8.578627785027493e-06 \n",
      "[2019-12-09 08:26:35.637 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.0004913850571028888 \n",
      "[2019-12-09 08:26:35.639 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.009018007665872574 \n",
      "[2019-12-09 08:26:35.641 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 8.578627785027493e-06 \n",
      "[2019-12-09 08:26:35.643 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 0.9657462239265442 \n",
      "[2019-12-09 08:26:35.648 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.1336489915847778 \n",
      "[2019-12-09 08:26:35.651 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 2.1447110611916287e-06 \n",
      "[2019-12-09 08:26:35.653 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.2710783779621124 \n",
      "[2019-12-09 08:26:35.654 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.71875 \n",
      "[2019-12-09 08:26:35.658 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.0050421953201294 \n",
      "[2019-12-09 08:26:35.661 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.5066399574279785 \n",
      "[2019-12-09 08:26:35.663 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 4.0634433389641345e-05 \n",
      "[2019-12-09 08:26:35.666 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.0025387934874743223 \n",
      "[2019-12-09 08:26:35.668 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.03522922471165657 \n",
      "[2019-12-09 08:26:35.670 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 4.0634433389641345e-05 \n",
      "[2019-12-09 08:26:35.672 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.0050421953201294 \n",
      "[2019-12-09 08:26:35.678 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.1770838499069214 \n",
      "[2019-12-09 08:26:35.681 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 1.0158791155845392e-05 \n",
      "[2019-12-09 08:26:35.683 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.6305144429206848 \n",
      "[2019-12-09 08:26:35.684 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.765625 \n",
      "[2019-12-09 08:26:35.690 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 0.9939102530479431 \n",
      "[2019-12-09 08:26:35.692 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.5199216604232788 \n",
      "[2019-12-09 08:26:35.694 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 0.0 \n",
      "[2019-12-09 08:26:35.696 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 1.1650556189124472e-05 \n",
      "[2019-12-09 08:26:35.698 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 3.5150722396792844e-05 \n",
      "[2019-12-09 08:26:35.700 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 0.0 \n",
      "[2019-12-09 08:26:35.702 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 0.9939102530479431 \n",
      "[2019-12-09 08:26:35.709 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.1923348903656006 \n",
      "[2019-12-09 08:26:35.712 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 0.0 \n",
      "[2019-12-09 08:26:35.713 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.0003987630771007389 \n",
      "[2019-12-09 08:26:35.714 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.825927734375 \n",
      "[2019-12-09 08:26:35.720 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.088844656944275 \n",
      "[2019-12-09 08:26:35.723 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.6272333860397339 \n",
      "[2019-12-09 08:26:35.725 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 2.722969657042995e-05 \n",
      "[2019-12-09 08:26:35.727 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.001537804026156664 \n",
      "[2019-12-09 08:26:35.729 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.020698264241218567 \n",
      "[2019-12-09 08:26:35.732 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 2.722969657042995e-05 \n",
      "[2019-12-09 08:26:35.734 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.088844656944275 \n",
      "[2019-12-09 08:26:35.743 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.284422755241394 \n",
      "[2019-12-09 08:26:35.746 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 6.807715180912055e-06 \n",
      "[2019-12-09 08:26:35.748 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.3499974310398102 \n",
      "[2019-12-09 08:26:35.749 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 8.525146484375 \n",
      "[2019-12-09 08:26:35.754 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.02464759349823 \n",
      "[2019-12-09 08:26:35.756 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.5811876058578491 \n",
      "[2019-12-09 08:26:35.758 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 8.817996643983861e-08 \n",
      "[2019-12-09 08:26:35.761 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 1.6243551726802252e-05 \n",
      "[2019-12-09 08:26:35.763 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 7.90026388131082e-05 \n",
      "[2019-12-09 08:26:35.765 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 8.817996643983861e-08 \n",
      "[2019-12-09 08:26:35.767 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.02464759349823 \n",
      "[2019-12-09 08:26:35.773 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.2369071245193481 \n",
      "[2019-12-09 08:26:35.776 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 2.2045314906904423e-08 \n",
      "[2019-12-09 08:26:35.777 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.0008547119796276093 \n",
      "[2019-12-09 08:26:35.779 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.89593505859375 \n",
      "[2019-12-09 08:26:35.783 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.0360491275787354 \n",
      "[2019-12-09 08:26:35.785 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.5861231088638306 \n",
      "[2019-12-09 08:26:35.787 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 2.320047087778221e-07 \n",
      "[2019-12-09 08:26:35.789 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 2.4218801627284847e-05 \n",
      "[2019-12-09 08:26:35.791 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.00021700286015402526 \n",
      "[2019-12-09 08:26:35.793 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 2.320047087778221e-07 \n",
      "[2019-12-09 08:26:35.795 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.0360491275787354 \n",
      "[2019-12-09 08:26:35.802 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.24196457862854 \n",
      "[2019-12-09 08:26:35.804 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 5.800203695116579e-08 \n",
      "[2019-12-09 08:26:35.806 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.002287123817950487 \n",
      "[2019-12-09 08:26:35.808 ip-172-16-62-40:11373 INFO <ipython-input-38-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 8.09173583984375 \n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    }
   ],
   "source": [
    "class Inputs(Rule):\n",
    "    def __init__(self, base_trial, ):\n",
    "        super().__init__(base_trial)  \n",
    "        self.tensors = collections.OrderedDict()  \n",
    "        \n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex='.*input'):\n",
    "            if \"relu\" not in tname:\n",
    "                try:\n",
    "                    tensor = self.base_trial.tensor(tname).value(step)\n",
    "                    if tname not in self.tensors:\n",
    "                        self.tensors[tname] = {}\n",
    "                 \n",
    "                    self.logger.info(f\" Tensor  {tname}  has inputs with variance: {np.var(tensor.flatten())} \")\n",
    "                    self.tensors[tname][step] = tensor\n",
    "                except:\n",
    "                    self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = Inputs(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print('The training has ended and there is no more data to be analyzed. This is expected behavior.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(rule.tensors, filename='images/layer_inputs.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/layer_inputs.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='images/layer_inputs.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer outputs\n",
    "This rule retrieves outputs of layers excluding activation outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-09 08:29:22.832 ip-172-16-62-40:11373 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2019-12-09 08:29:22.844 ip-172-16-62-40:11373 INFO rule_invoker.py:10] Started execution of rule Outputs at step 0\n",
      "[2019-12-09 08:29:22.845 ip-172-16-62-40:11373 INFO trial.py:197] Training has ended, will refresh one final time in 1 sec.\n",
      "[2019-12-09 08:29:23.847 ip-172-16-62-40:11373 INFO trial.py:209] Loaded all steps\n",
      "[2019-12-09 08:29:23.852 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 3.62184476852417 \n",
      "[2019-12-09 08:29:23.855 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 43.39231491088867 \n",
      "[2019-12-09 08:29:23.856 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 4567.81201171875 \n",
      "[2019-12-09 08:29:23.858 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 95591.2109375 \n",
      "[2019-12-09 08:29:23.860 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 4557619.5 \n",
      "[2019-12-09 08:29:23.862 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 58.34519577026367 \n",
      "[2019-12-09 08:29:23.863 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 4557619.5 \n",
      "[2019-12-09 08:29:23.866 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 4.631735801696777 \n",
      "[2019-12-09 08:29:23.868 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 58.34519577026367 \n",
      "[2019-12-09 08:29:23.869 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 5638512.0 \n",
      "[2019-12-09 08:29:23.877 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 0.7227692604064941 \n",
      "[2019-12-09 08:29:23.880 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 0.016288643702864647 \n",
      "[2019-12-09 08:29:23.882 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 2.577444553375244 \n",
      "[2019-12-09 08:29:23.883 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 32.2889404296875 \n",
      "[2019-12-09 08:29:23.885 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 724.1642456054688 \n",
      "[2019-12-09 08:29:23.887 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 0.05608796700835228 \n",
      "[2019-12-09 08:29:23.888 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 724.1642456054688 \n",
      "[2019-12-09 08:29:23.890 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.0086477994918823 \n",
      "[2019-12-09 08:29:23.892 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 0.05608796700835228 \n",
      "[2019-12-09 08:29:23.894 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 497.3372802734375 \n",
      "[2019-12-09 08:29:23.899 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 0.9883172512054443 \n",
      "[2019-12-09 08:29:23.902 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 0.00017379701603204012 \n",
      "[2019-12-09 08:29:23.903 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.040474407374858856 \n",
      "[2019-12-09 08:29:23.905 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.7851430773735046 \n",
      "[2019-12-09 08:29:23.906 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 14.333717346191406 \n",
      "[2019-12-09 08:29:23.908 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 0.0006950494716875255 \n",
      "[2019-12-09 08:29:23.910 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 14.333717346191406 \n",
      "[2019-12-09 08:29:23.912 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.2801284790039062 \n",
      "[2019-12-09 08:29:23.914 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 0.0006950494716875255 \n",
      "[2019-12-09 08:29:23.915 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 13.768226623535156 \n",
      "[2019-12-09 08:29:23.920 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.0273112058639526 \n",
      "[2019-12-09 08:29:23.923 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 2.1803927666042e-05 \n",
      "[2019-12-09 08:29:23.925 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.0055632335133850574 \n",
      "[2019-12-09 08:29:23.926 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.07210429757833481 \n",
      "[2019-12-09 08:29:23.928 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 1.1936274766921997 \n",
      "[2019-12-09 08:29:23.930 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 8.721276390133426e-05 \n",
      "[2019-12-09 08:29:23.931 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 1.1936274766921997 \n",
      "[2019-12-09 08:29:23.933 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.3154237270355225 \n",
      "[2019-12-09 08:29:23.935 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 8.721276390133426e-05 \n",
      "[2019-12-09 08:29:23.937 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 11.447471618652344 \n",
      "[2019-12-09 08:29:23.944 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.1476784944534302 \n",
      "[2019-12-09 08:29:23.946 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 4.299523880035849e-06 \n",
      "[2019-12-09 08:29:23.948 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.0011113934451714158 \n",
      "[2019-12-09 08:29:23.950 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.01590985804796219 \n",
      "[2019-12-09 08:29:23.951 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.3021492063999176 \n",
      "[2019-12-09 08:29:23.953 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 1.7197140550706536e-05 \n",
      "[2019-12-09 08:29:23.954 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.3021492063999176 \n",
      "[2019-12-09 08:29:23.957 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.485790729522705 \n",
      "[2019-12-09 08:29:23.958 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 1.7197140550706536e-05 \n",
      "[2019-12-09 08:29:23.959 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.05942179262638092 \n",
      "[2019-12-09 08:29:23.965 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.0794696807861328 \n",
      "[2019-12-09 08:29:23.968 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 2.295121521456167e-05 \n",
      "[2019-12-09 08:29:23.969 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.006315335631370544 \n",
      "[2019-12-09 08:29:23.971 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.11620697379112244 \n",
      "[2019-12-09 08:29:23.973 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 2.9819247722625732 \n",
      "[2019-12-09 08:29:23.974 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 9.179903281619772e-05 \n",
      "[2019-12-09 08:29:23.976 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 2.9819247722625732 \n",
      "[2019-12-09 08:29:23.978 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.3866266012191772 \n",
      "[2019-12-09 08:29:23.980 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 9.179903281619772e-05 \n",
      "[2019-12-09 08:29:23.981 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 8.616910934448242 \n",
      "[2019-12-09 08:29:23.986 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.1618295907974243 \n",
      "[2019-12-09 08:29:23.989 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 1.9754832464968786e-05 \n",
      "[2019-12-09 08:29:23.991 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.00497449841350317 \n",
      "[2019-12-09 08:29:23.992 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.07216133177280426 \n",
      "[2019-12-09 08:29:23.993 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.9713736772537231 \n",
      "[2019-12-09 08:29:23.995 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 7.9017409007065e-05 \n",
      "[2019-12-09 08:29:23.997 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.9713736772537231 \n",
      "[2019-12-09 08:29:23.999 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.4771150350570679 \n",
      "[2019-12-09 08:29:24.001 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 7.9017409007065e-05 \n",
      "[2019-12-09 08:29:24.002 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.12563079595565796 \n",
      "[2019-12-09 08:29:24.008 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.1046311855316162 \n",
      "[2019-12-09 08:29:24.010 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 2.5108283807639964e-06 \n",
      "[2019-12-09 08:29:24.012 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.0006167683750391006 \n",
      "[2019-12-09 08:29:24.014 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.007651651278138161 \n",
      "[2019-12-09 08:29:24.015 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.059586815536022186 \n",
      "[2019-12-09 08:29:24.017 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 1.0042845133284573e-05 \n",
      "[2019-12-09 08:29:24.018 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.059586815536022186 \n",
      "[2019-12-09 08:29:24.021 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.3983067274093628 \n",
      "[2019-12-09 08:29:24.022 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 1.0042845133284573e-05 \n",
      "[2019-12-09 08:29:24.024 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.009925417602062225 \n",
      "[2019-12-09 08:29:24.029 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.1302409172058105 \n",
      "[2019-12-09 08:29:24.032 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 8.028936235859874e-07 \n",
      "[2019-12-09 08:29:24.034 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.00020764600776601583 \n",
      "[2019-12-09 08:29:24.035 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.0033855850342661142 \n",
      "[2019-12-09 08:29:24.037 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.03743215650320053 \n",
      "[2019-12-09 08:29:24.040 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 3.2114867281052284e-06 \n",
      "[2019-12-09 08:29:24.041 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.03743215650320053 \n",
      "[2019-12-09 08:29:24.044 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.4355108737945557 \n",
      "[2019-12-09 08:29:24.045 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 3.2114867281052284e-06 \n",
      "[2019-12-09 08:29:24.047 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.18689489364624023 \n",
      "[2019-12-09 08:29:24.053 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.1336489915847778 \n",
      "[2019-12-09 08:29:24.055 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 2.1447110611916287e-06 \n",
      "[2019-12-09 08:29:24.057 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.0004913850571028888 \n",
      "[2019-12-09 08:29:24.059 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.009018007665872574 \n",
      "[2019-12-09 08:29:24.060 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.2710783779621124 \n",
      "[2019-12-09 08:29:24.062 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 8.578627785027493e-06 \n",
      "[2019-12-09 08:29:24.063 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.2710783779621124 \n",
      "[2019-12-09 08:29:24.065 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.4277024269104004 \n",
      "[2019-12-09 08:29:24.067 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 8.578627785027493e-06 \n",
      "[2019-12-09 08:29:24.069 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.06580298393964767 \n",
      "[2019-12-09 08:29:24.074 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.1770838499069214 \n",
      "[2019-12-09 08:29:24.077 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 1.0158791155845392e-05 \n",
      "[2019-12-09 08:29:24.079 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.0025387934874743223 \n",
      "[2019-12-09 08:29:24.080 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.03522922471165657 \n",
      "[2019-12-09 08:29:24.082 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.6305144429206848 \n",
      "[2019-12-09 08:29:24.084 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 4.0634433389641345e-05 \n",
      "[2019-12-09 08:29:24.085 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.6305144429206848 \n",
      "[2019-12-09 08:29:24.087 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.5066399574279785 \n",
      "[2019-12-09 08:29:24.089 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 4.0634433389641345e-05 \n",
      "[2019-12-09 08:29:24.090 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.3554143011569977 \n",
      "[2019-12-09 08:29:24.096 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.1923348903656006 \n",
      "[2019-12-09 08:29:24.099 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 0.0 \n",
      "[2019-12-09 08:29:24.101 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 1.1650556189124472e-05 \n",
      "[2019-12-09 08:29:24.103 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 3.5150722396792844e-05 \n",
      "[2019-12-09 08:29:24.104 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.0003987630771007389 \n",
      "[2019-12-09 08:29:24.107 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 0.0 \n",
      "[2019-12-09 08:29:24.108 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.0003987630771007389 \n",
      "[2019-12-09 08:29:24.111 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.5199216604232788 \n",
      "[2019-12-09 08:29:24.113 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 0.0 \n",
      "[2019-12-09 08:29:24.115 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.0004403489292599261 \n",
      "[2019-12-09 08:29:24.122 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.284422755241394 \n",
      "[2019-12-09 08:29:24.125 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 6.807715180912055e-06 \n",
      "[2019-12-09 08:29:24.126 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.001537804026156664 \n",
      "[2019-12-09 08:29:24.128 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.020698264241218567 \n",
      "[2019-12-09 08:29:24.130 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.3499974310398102 \n",
      "[2019-12-09 08:29:24.132 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 2.722969657042995e-05 \n",
      "[2019-12-09 08:29:24.134 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.3499974310398102 \n",
      "[2019-12-09 08:29:24.136 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.6272333860397339 \n",
      "[2019-12-09 08:29:24.138 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 2.722969657042995e-05 \n",
      "[2019-12-09 08:29:24.140 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.3973408639431 \n",
      "[2019-12-09 08:29:24.147 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.2369071245193481 \n",
      "[2019-12-09 08:29:24.149 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 2.2045314906904423e-08 \n",
      "[2019-12-09 08:29:24.151 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 1.6243551726802252e-05 \n",
      "[2019-12-09 08:29:24.154 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 7.90026388131082e-05 \n",
      "[2019-12-09 08:29:24.155 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.0008547119796276093 \n",
      "[2019-12-09 08:29:24.157 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 8.817996643983861e-08 \n",
      "[2019-12-09 08:29:24.159 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.0008547119796276093 \n",
      "[2019-12-09 08:29:24.162 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.5811876058578491 \n",
      "[2019-12-09 08:29:24.164 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 8.817996643983861e-08 \n",
      "[2019-12-09 08:29:24.165 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.0004789079539477825 \n",
      "[2019-12-09 08:29:24.173 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.24196457862854 \n",
      "[2019-12-09 08:29:24.176 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 5.800203695116579e-08 \n",
      "[2019-12-09 08:29:24.177 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 2.4218801627284847e-05 \n",
      "[2019-12-09 08:29:24.179 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.00021700286015402526 \n",
      "[2019-12-09 08:29:24.181 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.002287123817950487 \n",
      "[2019-12-09 08:29:24.183 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 2.320047087778221e-07 \n",
      "[2019-12-09 08:29:24.184 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.002287123817950487 \n",
      "[2019-12-09 08:29:24.187 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.5861231088638306 \n",
      "[2019-12-09 08:29:24.189 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 2.320047087778221e-07 \n",
      "[2019-12-09 08:29:24.190 ip-172-16-62-40:11373 INFO <ipython-input-43-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.0011275241849943995 \n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    }
   ],
   "source": [
    "class Outputs(Rule):\n",
    "    def __init__(self, base_trial, ):\n",
    "        super().__init__(base_trial)  \n",
    "        self.tensors = collections.OrderedDict() \n",
    "        \n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex='.*output'):\n",
    "            if \"relu\" not in tname:\n",
    "                try:\n",
    "                    tensor = self.base_trial.tensor(tname).value(step)\n",
    "                    if tname not in self.tensors:\n",
    "                        self.tensors[tname] = {}\n",
    "                 \n",
    "                    self.logger.info(f\" Tensor  {tname}  has inputs with variance: {np.var(tensor.flatten())} \")\n",
    "                    self.tensors[tname][step] = tensor\n",
    "                except:\n",
    "                    self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = Outputs(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print('The training has ended and there is no more data to be analyzed. This is expected behavior.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(rule.tensors, filename='images/layer_outputs.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/layer_outputs.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='images/layer_outputs.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison \n",
    "In the previous section we have looked at the distribution of gradients, activation outputs and weights of a model that has not trained well due to poor initialization. Now we will compare some of these distributions with a model that has been well intialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_script = 'mnist.py'\n",
    "hyperparameters = {'lr': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MXNet(role=sagemaker.get_execution_role(),\n",
    "                  base_job_name='mxnet',\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.m5.xlarge',\n",
    "                  train_volume_size=400,\n",
    "                  source_dir='src',\n",
    "                  entry_point=entry_point_script,\n",
    "                  hyperparameters=hyperparameters,\n",
    "                  framework_version='1.6.0',\n",
    "                  py_version='py3',\n",
    "                  debugger_hook_config = DebuggerHookConfig(\n",
    "                      s3_output_path=s3_bucket_for_tensors,  \n",
    "                      collection_configs=[\n",
    "                        CollectionConfig(\n",
    "                            name=\"all\",\n",
    "                            parameters={\n",
    "                                \"include_regex\": \".*\",\n",
    "                                \"save_interval\": \"100\"\n",
    "                            }\n",
    "                        )\n",
    "                     ]\n",
    "                   )\n",
    "                )\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get S3 path where tensors have been stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = estimator.latest_training_job.name\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=job_name)\n",
    "path = description['DebugHookConfig']['S3OutputPath'] + '/' + job_name + '/debug-output'\n",
    "print('Tensors are stored in: ', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tensors from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name2 = \"/tmp/{}_2\".format(path.split(\"/\")[-1])\n",
    "os.system(\"aws s3 cp --recursive {} {}\".format(path,folder_name2))\n",
    "print('Downloading tensors into folder: ', folder_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradients\n",
    "\n",
    "Lets compare distribution of gradients of the convolutional layers of both trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = create_trial(folder_name)\n",
    "rule = GradientsLayer(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print('The training has ended and there is no more data to be analyzed. This is expected behavior.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_gradients = {}\n",
    "dict_gradients['gradient/conv0_weight_bad_hyperparameters'] = rule.tensors['gradient/conv0_weight']\n",
    "dict_gradients['gradient/conv1_weight_bad_hyperparameters'] = rule.tensors['gradient/conv1_weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = create_trial(folder_name2)\n",
    "rule = GradientsLayer(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print('The training has ended and there is no more data to be analyzed. This is expected behavior.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_gradients['gradient/conv0_weight_good_hyperparameters'] = rule.tensors['gradient/conv0_weight']\n",
    "dict_gradients['gradient/conv1_weight_good_hyperparameters'] = rule.tensors['gradient/conv1_weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(dict_gradients, filename='images/gradients_comparison.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the poorly initalized model, gradients are fluctuating a lot leading to very high variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url='images/gradients_comparison.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation inputs\n",
    "\n",
    "Lets compare distribution of activation inputs of both trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = create_trial(folder_name)\n",
    "rule = ActivationInputs(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print('The training has ended and there is no more data to be analyzed. This is expected behavior.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_activation_inputs = {}\n",
    "dict_activation_inputs['conv0_relu_input_0_bad_hyperparameters'] = rule.tensors['conv0_relu_input_0']\n",
    "dict_activation_inputs['conv1_relu_input_0_bad_hyperparameters'] = rule.tensors['conv1_relu_input_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = create_trial(folder_name2)\n",
    "rule = ActivationInputs(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print('The training has ended and there is no more data to be analyzed. This is expected behavior.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_activation_inputs['conv0_relu_input_0_good_hyperparameters'] = rule.tensors['conv0_relu_input_0']\n",
    "dict_activation_inputs['conv1_relu_input_0_good_hyperparameters'] = rule.tensors['conv1_relu_input_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(dict_activation_inputs, filename='images/activation_inputs_comparison.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of activation inputs into first activation layer `conv0_relu_input_0` look quite similar in both trials. However in the case of the second layer they drastically differ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url='images/activation_inputs_comparison.gif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
